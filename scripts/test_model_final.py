#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import tensorflow as tf
import numpy as np
import pandas as pd
import cv2
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix  # roc_curve, auc supprim√©s
from sklearn.preprocessing import label_binarize

# ----- Configuration -----
# Chemin du mapping de test (assurez-vous que ce fichier contient les colonnes "image_path" et "audio_path")
TEST_CSV = "data/audio/test_image_audio_mapping.csv"

# Chemins des mod√®les individuels
IMAGE_MODEL_PATH = "models/image_classifier.keras"
AUDIO_MODEL_PATH = "models/audio_classifier.keras"

# ----- Chargement des mod√®les individuels -----
print("üîÑ Chargement du mod√®le image...")
image_model = tf.keras.models.load_model(IMAGE_MODEL_PATH)
print("‚úÖ Mod√®le image charg√©.")

print("üîÑ Chargement du mod√®le audio...")
audio_model = tf.keras.models.load_model(AUDIO_MODEL_PATH)
print("‚úÖ Mod√®le audio charg√©.")

# ----- Fonctions de pr√©traitement -----
def preprocess_image(image_path):
    """Charge et pr√©traite une image en niveaux de gris."""
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        return None
    img = cv2.resize(img, (64, 64)) / 255.0
    return img.reshape(1, 64, 64, 1)

def preprocess_audio(audio_path):
    """
    Charge le spectrogramme pr√©-g√©n√©r√© correspondant au fichier audio.
    On suppose que le chemin audio est de la forme :
        data/audio/cleaned/...
    et que le spectrogramme est pr√©-g√©n√©r√© dans :
        data/audio/spectrograms/...
    avec l'extension .wav remplac√©e par .png.
    """
    spec_path = audio_path.replace("cleaned", "spectrograms").replace(".wav", ".png")
    if not os.path.exists(spec_path):
        print(f"‚ùå Spectrogramme introuvable pour {audio_path} -> {spec_path}")
        return None
    spec_img = cv2.imread(spec_path, cv2.IMREAD_GRAYSCALE)
    if spec_img is None:
        return None
    spec_img = cv2.resize(spec_img, (64, 64)) / 255.0
    return spec_img.reshape(1, 64, 64, 1)

# ----- Chargement du mapping de test -----
print("üîÑ Chargement du mapping de test...")
test_df = pd.read_csv(TEST_CSV)

X_images, X_audio = [], []
y_true = []  # √âtiquette "virtuelle" d√©riv√©e du nom de fichier

for _, row in test_df.iterrows():
    img_path = row["image_path"]
    audio_path = row["audio_path"]
    if not os.path.exists(img_path) or not os.path.exists(audio_path):
        continue
    X_img = preprocess_image(img_path)
    X_aud = preprocess_audio(audio_path)
    if X_img is None or X_aud is None:
        continue
    X_images.append(X_img)
    X_audio.append(X_aud)
    # D√©finir le label √† partir des chemins :
    # Si les deux chemins contiennent "cats", label = 0 ; s'ils contiennent "dogs", label = 1 ; sinon, label = 2.
    if "cats" in img_path.lower() and "cats" in audio_path.lower():
        y_true.append(0)
    elif "dogs" in img_path.lower() and "dogs" in audio_path.lower():
        y_true.append(1)
    else:
        y_true.append(2)

if len(X_images) == 0 or len(X_audio) == 0:
    print("‚ùå Aucun √©chantillon de test valide trouv√©.")
    exit()

# Convertir les listes en tenseurs
X_images = np.vstack(X_images)
X_audio = np.vstack(X_audio)
y_true = np.array(y_true)

print(f"üîÑ Nombre d'√©chantillons de test utilis√©s : {X_images.shape[0]}")

# ----- Pr√©dictions individuelles -----
# Pr√©diction du mod√®le image (sortie sigmo√Øde, seuil 0.5)
image_preds_prob = image_model.predict(X_images)
image_preds = (image_preds_prob > 0.5).astype(int).reshape(-1)

# Pr√©diction du mod√®le audio (sortie sigmo√Øde, seuil 0.5)
audio_preds_prob = audio_model.predict(X_audio)
audio_preds = (audio_preds_prob > 0.5).astype(int).reshape(-1)

# ----- Fusion des pr√©dictions -----
# Si les deux pr√©dictions (image et audio) sont identiques, la pr√©diction finale est cette valeur (0 ou 1).
# Sinon, on consid√®re que le mod√®le est en d√©saccord et on d√©finit la pr√©diction finale comme 2 (Erreur).
y_pred_final = []
for img_pred, aud_pred in zip(image_preds, audio_preds):
    if img_pred == aud_pred:
        y_pred_final.append(img_pred)
    else:
        y_pred_final.append(2)
y_pred_final = np.array(y_pred_final)

# ----- √âvaluation -----
label_names = {0: "Chat", 1: "Chien", 2: "Erreur"}
target_names = [label_names[0], label_names[1], label_names[2]]

print("\nüìå Rapport de classification :")
print(classification_report(y_true, y_pred_final, target_names=target_names))

conf_matrix = confusion_matrix(y_true, y_pred_final, labels=[0, 1, 2])
plt.figure(figsize=(6,6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
            xticklabels=target_names, yticklabels=target_names)
plt.xlabel("Pr√©dictions")
plt.ylabel("Vraies Classes")
plt.title("Matrice de Confusion")
plt.show()


accuracy = np.mean(y_pred_final == y_true) * 100
print(f"\nüéØ Test Accuracy (Ensemble): {accuracy:.2f}%")

# ----- Sauvegarde des r√©sultats -----
OUTPUT_RESULTS = "test_results_v7.csv"
test_df["prediction"] = y_pred_final
test_df.to_csv(OUTPUT_RESULTS, index=False)
print(f"\n‚úÖ R√©sultats sauvegard√©s dans {OUTPUT_RESULTS}")
