import os
import numpy as np
import tensorflow as tf
import pandas as pd
import cv2
import librosa
import librosa.display
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# ğŸ“‚ DÃ©finition des chemins
MODEL_PATH = "models/audio_image_classifier_v6.keras"
TEST_CSV = "data/audio/test_image_audio_mapping.csv"

# VÃ©rifier l'existence des fichiers
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"ğŸš¨ ModÃ¨le introuvable : {MODEL_PATH}")
if not os.path.exists(TEST_CSV):
    raise FileNotFoundError(f"ğŸš¨ Fichier de test introuvable : {TEST_CSV}")

# âœ… Charger le modÃ¨le
print("ğŸ”„ Chargement du modÃ¨le V6...")
model = tf.keras.models.load_model(MODEL_PATH)
print("âœ… ModÃ¨le chargÃ© avec succÃ¨s !")

# ğŸ› ParamÃ¨tres d'image et audio
IMG_SIZE = (64, 64)
SR = 22050  # FrÃ©quence d'Ã©chantillonnage
N_MELS = 128  # Nombre de bandes mel
DURATION = 2  # DurÃ©e en secondes

# ğŸ¨ Fonction pour convertir un fichier audio en spectrogramme
def audio_to_spectrogram(audio_path):
    y, sr = librosa.load(audio_path, sr=SR, duration=DURATION)
    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)
    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)

    # Convertir en format image
    fig, ax = plt.subplots(figsize=(3, 3))
    ax.set_axis_off()
    librosa.display.specshow(spectrogram_db, sr=sr, x_axis="time", y_axis="mel")
    
    fig.canvas.draw()
    img_array = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
    img_array = img_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))
    
    plt.close(fig)
    
    # Convertir en Ã©chelle de gris et redimensionner
    img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    img_resized = cv2.resize(img_gray, IMG_SIZE) / 255.0
    return img_resized

# ğŸ“‚ Chargement des donnÃ©es de test
test_df = pd.read_csv(TEST_CSV)
X_audio, X_images, y_true = [], [], []

print("ğŸ”„ PrÃ©traitement des donnÃ©es de test...")



import matplotlib.pyplot as plt

def visualize_input(image_path, spectrogram_path):
    fig, axes = plt.subplots(1, 2, figsize=(8, 4))

    # Affichage de l'image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    axes[0].imshow(img, cmap="gray")
    axes[0].set_title("Image")

    # Affichage du spectrogramme
    spec = cv2.imread(spectrogram_path, cv2.IMREAD_GRAYSCALE)
    axes[1].imshow(spec, cmap="gray")
    axes[1].set_title("Spectrogramme")

    plt.show()

# Avant dâ€™envoyer au modÃ¨le, affichons les donnÃ©es chargÃ©es
visualize_input(image_path, spectrogram_path)

for _, row in test_df.iterrows():
    img_path, audio_path = row["image_path"], row["audio_path"]

    # VÃ©rifier l'existence des fichiers
    if not os.path.exists(img_path) or not os.path.exists(audio_path):
        print(f"âš ï¸ Fichier manquant : {img_path} ou {audio_path}")
        continue

    # Chargement et prÃ©traitement de l'image
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, IMG_SIZE) / 255.0

    # Conversion de l'audio en spectrogramme
    spec_img = audio_to_spectrogram(audio_path)

    X_images.append(img)
    X_audio.append(spec_img)

    # DÃ©finir la classe cible (0 = Chat, 1 = Chien, 2 = Erreur)
    if "cats" in img_path and "cats" in audio_path:
        y_true.append(0)  # Chat
    elif "dogs" in img_path and "dogs" in audio_path:
        y_true.append(1)  # Chien
    else:
        y_true.append(2)  # Erreur (mismatch image-son)

# ğŸ“¦ Conversion en tenseurs
X_audio = np.array(X_audio).reshape(-1, 64, 64, 1)
X_images = np.array(X_images).reshape(-1, 64, 64, 1)
y_true = np.array(y_true)

# ğŸš€ PrÃ©diction avec le modÃ¨le
print("ğŸ”„ PrÃ©dictions en cours...")
y_pred = model.predict([X_images, X_audio])
y_pred = np.argmax(y_pred, axis=1)  # Convertir en labels 0, 1 ou 2

# ğŸ“Š Calcul des mÃ©triques
accuracy = accuracy_score(y_true, y_pred)
conf_matrix = confusion_matrix(y_true, y_pred)
class_report = classification_report(y_true, y_pred, target_names=["Chat", "Chien", "Erreur"])

# ğŸ“œ Affichage des rÃ©sultats
print("\nğŸ“Š **RÃ©sumÃ© des Performances :**")
print(f"ğŸ¯ **Test Accuracy:** {accuracy:.2%}\n")

print("ğŸ“Œ **Matrice de Confusion :**")
print(conf_matrix)

print("\nğŸ“œ **Rapport de Classification :**")
print(class_report)

# ğŸ’¾ Sauvegarde des rÃ©sultats
results_df = pd.DataFrame({"Image_Path": test_df["image_path"], "Audio_Path": test_df["audio_path"], "True_Label": y_true, "Predicted_Label": y_pred})
results_df.to_csv("test_results_v6.csv", index=False)
print("âœ… RÃ©sultats sauvegardÃ©s dans test_results_v6.csv")